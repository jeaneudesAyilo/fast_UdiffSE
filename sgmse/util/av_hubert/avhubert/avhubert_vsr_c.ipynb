{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l2iJc6i9rPli"
   },
   "source": [
    "# Hands-on tutorial for AV-HuBERT\n",
    "\n",
    "In this notebook, we show-case how to use pre-trained models for:\n",
    "* lip reading\n",
    "* feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eSMfe7P_rZsn"
   },
   "source": [
    "## Preliminaries\n",
    "This section installs necessary python packages for the other sections. Run it first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PSadN0wxrkhf",
    "outputId": "50f855a6-5ad0-4102-ea17-edd7f911442e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/srv/storage/talc3@storage4.nancy.grid5000.fr/multispeech/calcul/users/jayilo\n",
      "Cloning into 'av_hubert'...\n",
      "remote: Enumerating objects: 146, done.\u001b[K\n",
      "remote: Counting objects: 100% (35/35), done.\u001b[K\n",
      "remote: Compressing objects: 100% (23/23), done.\u001b[K\n",
      "remote: Total 146 (delta 17), reused 25 (delta 12), pack-reused 111\u001b[K\n",
      "Receiving objects: 100% (146/146), 4.65 MiB | 1.37 MiB/s, done.\n",
      "Resolving deltas: 100% (63/63), done.\n",
      "/srv/storage/talc3@storage4.nancy.grid5000.fr/multispeech/calcul/users/jayilo/av_hubert\n",
      "Submodule 'fairseq' (https://github.com/pytorch/fairseq) registered for path 'fairseq'\n",
      "Cloning into '/srv/storage/talc3@storage4.nancy.grid5000.fr/multispeech/calcul/users/jayilo/av_hubert/fairseq'...\n",
      "Submodule path 'fairseq': checked out 'afc77bdf4bb51453ce76f1572ef2ee6ddcda8eeb'\n",
      "Requirement already satisfied: scipy in /home/jayilo/anaconda3/lib/python3.8/site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /home/jayilo/anaconda3/lib/python3.8/site-packages (from scipy) (1.19.2)\n",
      "Requirement already satisfied: sentencepiece in /home/jayilo/anaconda3/lib/python3.8/site-packages (0.1.99)\n",
      "Requirement already satisfied: python_speech_features in /home/jayilo/anaconda3/lib/python3.8/site-packages (0.6)\n",
      "Requirement already satisfied: scikit-video in /home/jayilo/anaconda3/lib/python3.8/site-packages (1.1.11)\n",
      "Requirement already satisfied: pillow in /home/jayilo/anaconda3/lib/python3.8/site-packages (from scikit-video) (8.0.1)\n",
      "Requirement already satisfied: numpy in /home/jayilo/anaconda3/lib/python3.8/site-packages (from scikit-video) (1.19.2)\n",
      "Requirement already satisfied: scipy in /home/jayilo/anaconda3/lib/python3.8/site-packages (from scikit-video) (1.5.2)\n",
      "/srv/storage/talc3@storage4.nancy.grid5000.fr/multispeech/calcul/users/jayilo/av_hubert/fairseq\n",
      "Processing /srv/storage/talc3@storage4.nancy.grid5000.fr/multispeech/calcul/users/jayilo/av_hubert/fairseq\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: regex in /home/jayilo/anaconda3/lib/python3.8/site-packages (from fairseq==1.0.0a0) (2020.10.15)\n",
      "Collecting torch\n",
      "  Using cached torch-2.0.1-cp38-cp38-manylinux1_x86_64.whl (619.9 MB)\n",
      "Requirement already satisfied: numpy; python_version >= \"3.7\" in /home/jayilo/anaconda3/lib/python3.8/site-packages (from fairseq==1.0.0a0) (1.19.2)\n",
      "Requirement already satisfied: tqdm in /home/jayilo/anaconda3/lib/python3.8/site-packages (from fairseq==1.0.0a0) (4.50.2)\n",
      "Requirement already satisfied: omegaconf<2.1 in /home/jayilo/anaconda3/lib/python3.8/site-packages (from fairseq==1.0.0a0) (2.0.6)\n",
      "Requirement already satisfied: cffi in /home/jayilo/anaconda3/lib/python3.8/site-packages (from fairseq==1.0.0a0) (1.14.3)\n",
      "Requirement already satisfied: cython in /home/jayilo/anaconda3/lib/python3.8/site-packages (from fairseq==1.0.0a0) (0.29.21)\n",
      "Requirement already satisfied: sacrebleu>=1.4.12 in /home/jayilo/anaconda3/lib/python3.8/site-packages (from fairseq==1.0.0a0) (2.3.1)\n",
      "Collecting hydra-core<1.1\n",
      "  Using cached hydra_core-1.0.7-py3-none-any.whl (123 kB)\n",
      "Requirement already satisfied: jinja2 in /home/jayilo/anaconda3/lib/python3.8/site-packages (from torch->fairseq==1.0.0a0) (2.11.2)\n",
      "Requirement already satisfied: typing-extensions in /home/jayilo/anaconda3/lib/python3.8/site-packages (from torch->fairseq==1.0.0a0) (3.7.4.3)\n",
      "Requirement already satisfied: filelock in /home/jayilo/anaconda3/lib/python3.8/site-packages (from torch->fairseq==1.0.0a0) (3.0.12)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/jayilo/anaconda3/lib/python3.8/site-packages (from torch->fairseq==1.0.0a0) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/jayilo/anaconda3/lib/python3.8/site-packages (from torch->fairseq==1.0.0a0) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/jayilo/anaconda3/lib/python3.8/site-packages (from torch->fairseq==1.0.0a0) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/jayilo/anaconda3/lib/python3.8/site-packages (from torch->fairseq==1.0.0a0) (11.7.91)\n",
      "Requirement already satisfied: sympy in /home/jayilo/anaconda3/lib/python3.8/site-packages (from torch->fairseq==1.0.0a0) (1.6.2)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/jayilo/anaconda3/lib/python3.8/site-packages (from torch->fairseq==1.0.0a0) (10.2.10.91)\n",
      "Requirement already satisfied: triton==2.0.0; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/jayilo/anaconda3/lib/python3.8/site-packages (from torch->fairseq==1.0.0a0) (2.0.0)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/jayilo/anaconda3/lib/python3.8/site-packages (from torch->fairseq==1.0.0a0) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/jayilo/anaconda3/lib/python3.8/site-packages (from torch->fairseq==1.0.0a0) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/jayilo/anaconda3/lib/python3.8/site-packages (from torch->fairseq==1.0.0a0) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/jayilo/anaconda3/lib/python3.8/site-packages (from torch->fairseq==1.0.0a0) (2.14.3)\n",
      "Requirement already satisfied: networkx in /home/jayilo/anaconda3/lib/python3.8/site-packages (from torch->fairseq==1.0.0a0) (2.5)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/jayilo/anaconda3/lib/python3.8/site-packages (from torch->fairseq==1.0.0a0) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /home/jayilo/anaconda3/lib/python3.8/site-packages (from torch->fairseq==1.0.0a0) (11.7.99)\n",
      "Requirement already satisfied: PyYAML>=5.1.* in /home/jayilo/anaconda3/lib/python3.8/site-packages (from omegaconf<2.1->fairseq==1.0.0a0) (5.3.1)\n",
      "Requirement already satisfied: pycparser in /home/jayilo/anaconda3/lib/python3.8/site-packages (from cffi->fairseq==1.0.0a0) (2.20)\n",
      "Requirement already satisfied: portalocker in /home/jayilo/anaconda3/lib/python3.8/site-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0) (2.7.0)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /home/jayilo/anaconda3/lib/python3.8/site-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0) (0.9.0)\n",
      "Requirement already satisfied: colorama in /home/jayilo/anaconda3/lib/python3.8/site-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0) (0.4.4)\n",
      "Requirement already satisfied: lxml in /home/jayilo/anaconda3/lib/python3.8/site-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0) (4.6.1)\n",
      "Processing /home/jayilo/.cache/pip/wheels/c8/d0/ab/d43c02eaddc5b9004db86950802442ad9a26f279c619e28da0/antlr4_python3_runtime-4.8-py3-none-any.whl\n",
      "Collecting importlib-resources; python_version < \"3.9\"\n",
      "  Using cached importlib_resources-5.12.0-py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/jayilo/anaconda3/lib/python3.8/site-packages (from jinja2->torch->fairseq==1.0.0a0) (1.1.1)\n",
      "Requirement already satisfied: wheel in /home/jayilo/anaconda3/lib/python3.8/site-packages (from nvidia-cusparse-cu11==11.7.4.91; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch->fairseq==1.0.0a0) (0.35.1)\n",
      "Requirement already satisfied: setuptools in /home/jayilo/anaconda3/lib/python3.8/site-packages (from nvidia-cusparse-cu11==11.7.4.91; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch->fairseq==1.0.0a0) (50.3.1.post20201107)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/jayilo/anaconda3/lib/python3.8/site-packages (from sympy->torch->fairseq==1.0.0a0) (1.1.0)\n",
      "Requirement already satisfied: cmake in /home/jayilo/anaconda3/lib/python3.8/site-packages (from triton==2.0.0; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch->fairseq==1.0.0a0) (3.26.3)\n",
      "Requirement already satisfied: lit in /home/jayilo/anaconda3/lib/python3.8/site-packages (from triton==2.0.0; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch->fairseq==1.0.0a0) (16.0.5.post0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/jayilo/anaconda3/lib/python3.8/site-packages (from networkx->torch->fairseq==1.0.0a0) (4.4.2)\n",
      "Requirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in /home/jayilo/anaconda3/lib/python3.8/site-packages (from importlib-resources; python_version < \"3.9\"->hydra-core<1.1->fairseq==1.0.0a0) (3.4.0)\n",
      "Building wheels for collected packages: fairseq\n",
      "  Building wheel for fairseq (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fairseq: filename=fairseq-1.0.0a0-cp38-cp38-linux_x86_64.whl size=2341435 sha256=870d5f7d3bd1a1b0bd231a31b16d63c78588d6d221f9fc7fc821b96786a662c1\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-iz2mvg2b/wheels/14/e5/47/c92134931fa50e9a049bf6b80a23a351ab32863673016c9759\n",
      "Successfully built fairseq\n",
      "Installing collected packages: torch, antlr4-python3-runtime, importlib-resources, hydra-core, fairseq\n",
      "Successfully installed antlr4-python3-runtime-4.8 fairseq-1.0.0a0 hydra-core-1.0.7 importlib-resources-5.12.0 torch-2.0.1\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "%cd /srv/storage/talc3@storage4.nancy.grid5000.fr/multispeech/calcul/users/jayilo\n",
    "\n",
    "!git clone https://github.com/facebookresearch/av_hubert.git\n",
    "\n",
    "%cd av_hubert\n",
    "!git submodule init\n",
    "!git submodule update\n",
    "!pip install scipy\n",
    "!pip install sentencepiece\n",
    "!pip install python_speech_features\n",
    "!pip install scikit-video\n",
    "\n",
    "%cd fairseq\n",
    "!pip install ./"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zbHzx965EeR1"
   },
   "source": [
    "## Import a pre-trained model\n",
    "This section illustrates how to load a pre-trained model and use it for inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "inwnJy3v44Em"
   },
   "source": [
    "1. Download a model checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MnfDD2kbEjU4",
    "outputId": "496d34d4-6d8e-4896-da92-cec017f5569f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/srv/storage/talc3@storage4.nancy.grid5000.fr/multispeech/calcul/users/jayilo/av_hubert/fairseq\n",
      "--2023-06-05 16:09:31--  https://dl.fbaipublicfiles.com/avhubert/model/lrs3_vox/vsr/base_vox_433h.pt\n",
      "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 18.164.52.45, 18.164.52.29, 18.164.52.20, ...\n",
      "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|18.164.52.45|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1928063847 (1.8G) [binary/octet-stream]\n",
      "Saving to: ‘/srv/storage/talc3@storage4.nancy.grid5000.fr/multispeech/calcul/users/jayilo/pretrained_model/finetune-model.pt’\n",
      "\n",
      "/srv/storage/talc3@ 100%[===================>]   1.79G   267MB/s    in 7.4s    \n",
      "\n",
      "2023-06-05 16:09:38 (249 MB/s) - ‘/srv/storage/talc3@storage4.nancy.grid5000.fr/multispeech/calcul/users/jayilo/pretrained_model/finetune-model.pt’ saved [1928063847/1928063847]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "%mkdir -p /srv/storage/talc3@storage4.nancy.grid5000.fr/multispeech/calcul/users/jayilo/pretrained_model\n",
    "!wget https://dl.fbaipublicfiles.com/avhubert/model/lrs3_vox/vsr/base_vox_433h.pt -O /srv/storage/talc3@storage4.nancy.grid5000.fr/multispeech/calcul/users/jayilo/pretrained_model/finetune-model.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z96Tm4JSGzM1"
   },
   "source": [
    "3. Extract visual feature with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "_Ptq1kBqLUH1"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "import cv2\n",
    "import tempfile\n",
    "import torch\n",
    "import utils as avhubert_utils\n",
    "from argparse import Namespace\n",
    "import fairseq\n",
    "from fairseq import checkpoint_utils, options, tasks, utils\n",
    "#from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uXUM-hEqRHcP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "XFI1HegyvrYR"
   },
   "outputs": [],
   "source": [
    "def load_array(path):\n",
    "  arr = np.load(path )\n",
    "  arr = np.transpose(arr.reshape(67,67,-1),axes=(1,0,2) )\n",
    "  arr = torch.from_numpy(np.transpose(arr.reshape(67,67,-1),axes=(2,0,1) ))\n",
    "  arr = torch.FloatTensor(arr)\n",
    "  #plt.imshow(arr[0,...], cmap='gray')\n",
    "  #plt.show()\n",
    "  #print(arr.shape); print(arr.max())\n",
    "  return arr\n",
    "\n",
    "def load_array_2(path,ind=0):\n",
    "  import torchvision.transforms as trf\n",
    "  arr = np.load(path )\n",
    "  arr = np.transpose(arr.reshape(67,67,-1),axes=(1,0,2) )\n",
    "  arr = trf.ToTensor()(arr)\n",
    "  plt.imshow(arr[ind,...], cmap='gray')\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cHIz78eefwqm",
    "outputId": "bd6d210b-98ec-4276-f8f5-900d079cc06c"
   },
   "outputs": [],
   "source": [
    "\n",
    "def extract_visual_feature(video_path, ckpt_path, user_dir, is_finetune_ckpt=False):\n",
    "  utils.import_user_module(Namespace(user_dir=user_dir))\n",
    "  models, saved_cfg, task = checkpoint_utils.load_model_ensemble_and_task([ckpt_path])\n",
    "  #frames = #avhubert_utils.load_video(video_path)\n",
    "  print(f\"task, {task}\")\n",
    "  print(f\"saved_cfg, {saved_cfg}\")\n",
    "      \n",
    "  frames = load_array(video_path)  \n",
    "  #print(f\"frames.shape {frames.shape}\")\n",
    "\n",
    "  frames = torch.FloatTensor(frames).unsqueeze(dim=0).unsqueeze(dim=0).cuda()\n",
    "  model = models[0]\n",
    "  if hasattr(models[0], 'decoder'):\n",
    "    print(f\"Checkpoint: fine-tuned\")\n",
    "    model = models[0].encoder.w2v_model\n",
    "  else:\n",
    "    print(f\"Checkpoint: pre-trained w/o fine-tuning\")\n",
    "  model.cuda()\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    # Specify output_layer if you want to extract feature of an intermediate layer\n",
    "    feature, _ = model.extract_finetune(source={'video': frames, 'audio': None}, padding_mask=None, output_layer=None)\n",
    "    feature = feature.squeeze(dim=0)\n",
    "  #print(f\"Video feature shape: {feature.shape}\")\n",
    "  return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "JKgP1Rc9FMCc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vd--vEgG2Tgt",
    "outputId": "8dd29b80-323e-4131-8223-9dc6c501bb00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task, <avhubert.hubert_pretraining.AVHubertPretrainingTask object at 0x7efb90b96340>\n",
      "saved_cfg, {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': None, 'tensorboard_logdir': 'tblog', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/private/home/bshi/code/fairseq-py/examples/av_hubert/model', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 8, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://learnfair0873:29671', 'distributed_port': 29671, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 2, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 1000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 45000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [1], 'lr': [0.001], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 2, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 8}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'av_hubert_seq2seq', 'w2v_path': '/checkpoint/bshi/data/lrs3//model-ckpt/base-vox/pretrain/av.pt', 'apply_mask': False, 'mask_selection': 'static', 'mask_length': 10, 'mask_other': 0, 'mask_prob': 0.75, 'mask_channel_selection': 'static', 'mask_channel_length': 64, 'mask_channel_other': 0, 'mask_channel_prob': 0.5, 'layerdrop': 0.1, 'dropout': 0.0, 'activation_dropout': 0.1, 'attention_dropout': 0.0, 'feature_grad_mult': 1.0, 'decoder_layers': 6, 'decoder_dropout': 0.1, 'decoder_attention_dropout': 0.0, 'decoder_activation_dropout': 0.1, 'freeze_finetune_updates': 22500, 'share_decoder_input_output_embed': True, 'decoder_normalize_before': True, 'w2v_args': {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/private/home/bshi/code/fairseq-py/examples/av_hubert/model', 'empty_cache_freq': 10000, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 32, 'distributed_num_procs': 8, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://learnfair1212:29671', 'distributed_port': 29671, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 1000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 5, 'validate_interval_updates': 10000, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 1000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 800000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.002], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 25000, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 32}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'av_hubert', 'label_rate': 25, 'skip_masked': False, 'skip_nomask': False, 'mask_prob_image': 0.3, 'mask_length_image': 5, 'mask_prob_audio': 0.8, 'mask_length_audio': 10, 'extractor_mode': 'default', 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'final_dim': 256, 'encoder_layerdrop': 0.05, 'dropout_input': 0.1, 'dropout_features': 0.1, 'dropout': 0.1, 'attention_dropout': 0.1, 'feature_grad_mult': 0.1, 'untie_final_proj': True, 'activation_dropout': 0.0, 'layer_norm_first': True, 'audio_feat_dim': 104, 'modality_dropout': 0.5, 'audio_dropout': 0.5, 'modality_fuse': 'concat', 'selection_type': 'same_seq', 'masking_type': 'input'}, 'task': {'_name': 'av_hubert_pretraining', 'data': '/checkpoint/bshi/data/lrs3//avsvox/en-vox-multimodal-tsv/', 'label_dir': '/checkpoint/bshi/data/lrs3//video/hubert/stitch-iters/envox-iter4-l12c2000/', 'labels': ['km'], 'label_rate': 25, 'sample_rate': 25, 'max_sample_size': 2000, 'min_sample_size': 5, 'pad_audio': False, 'random_crop': True, 'normalize': True, 'input_modality': 'image', 'image_aug': True, 'stack_order_audio': 4, 'max_trim_sample_size': 400}, 'criterion': {'_name': 'av_hubert', 'pred_masked_weight': 1.0, 'pred_nomask_weight': 1.0, 'loss_weights': [10]}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'tpu': False, 'lr': [0.002]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 64000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 800000, 'lr': [0.002]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}}, 'task': {'_name': 'av_hubert_pretraining', 'is_s2s': True, 'data': '/checkpoint/bshi/data/lrs3//exp/ls-hubert/tune-modality/all_tsv/', 'label_dir': '/checkpoint/bshi/data/lrs3//exp/ls-hubert/tune-modality/all_bpe/unigram1000/', 'normalize': True, 'labels': ['wrd'], 'single_target': True, 'stack_order_audio': 4, 'tokenizer_bpe_name': 'sentencepiece', 'max_sample_size': 500, 'modalities': ['video'], 'image_aug': True, 'pad_audio': True, 'random_crop': False, 'tokenizer_bpe_model': '/checkpoint/bshi/data/lrs3//lang/spm/spm_unigram1000.model', 'fine_tuning': True}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': True, 'ignore_prefix_size': 0, 'sentence_avg': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'tpu': False, 'lr': [0.001]}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 15000, 'hold_steps': 0, 'decay_steps': 30000, 'phase_ratio': None, 'init_lr_scale': 0.01, 'final_lr_scale': 0.05, 'max_update': 45000, 'lr': [0.001]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}\n",
      "Checkpoint: fine-tuned\n"
     ]
    }
   ],
   "source": [
    "mouth_roi_path = \"/srv/storage/talc3@storage4.nancy.grid5000.fr/multispeech/calcul/users/jayilo/sa1Raw.npy\"\n",
    "ckpt_path = \"/srv/storage/talc3@storage4.nancy.grid5000.fr/multispeech/calcul/users/jayilo/pretrained_model/finetune-model.pt\"\n",
    "user_dir = \"/srv/storage/talc3@storage4.nancy.grid5000.fr/multispeech/calcul/users/jayilo/av_hubert/avhubert\"\n",
    "\n",
    "feature = extract_visual_feature(mouth_roi_path, ckpt_path, user_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "yyeUsoyUF_dm"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([155, 768])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
