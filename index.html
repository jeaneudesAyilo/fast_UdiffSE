<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Audio Table</title>
    <style>
        table {
            width: 80%;
            border-collapse: collapse;
            margin: 17px 0;
        }
        th, td {
            border: 3px solid #dddddd;
            text-align: center;
            padding: 5px;
        }
        th {
            background-color: #f2f2f2;
        }
    </style>
</head>
<body>


    <div id="post-3436" class="clearfix post post-3436 page type-page status-publish hentry nodate item-wrap">
		
        <div class="entry clearfix">                
            
                      
                    
                    <div class="entry-content clearfix">    

    <h1 class="post-title entry-title" style="text-align: center;"><strong>Unsupervised Speech Enhancement </strong><strong style="color: inherit; font-family: inherit;">with Diffusion-based Generative Models</strong></h1>
    <p style="text-align: center;">Jean-Eudes Ayilo, Mostafa Sadeghi, Romain Serizel and Xavier Alameda-Pineda</p>
    
    <p style="text-align: justify;"><strong>Abstract.</strong> This paper proposes a new unsupervised approach for audio-visual speech enhancement (AVSE), utilizing a diffusion-based generative model for clean speech alongside a non-negative matrix factorization (NMF) model for noise. Specifically, the diffusion model is first pre-trained with clean speech, conditioned on the associated video data, to simulate speech generative distribution. Then, it is combined with the NMF model during testing to estimate the clean speech through iterative expectation maximization (EM), which involves a diffusion-based posterior sampling E-step. This approach extends a method previously developed for audio-only diffusion-based unsupervised speech enhancement. Our contributions include adapting this audio-only framework for the audio-visual scenario and developing a fast inference algorithm. Experimental results demonstrate the effectiveness of the proposed AVSE approach over the audio-only method and show that the proposed approach makes a better compromise between inference speed and performance compared with previous approach.</p>
    <p>Â </p>

</body>
</html>